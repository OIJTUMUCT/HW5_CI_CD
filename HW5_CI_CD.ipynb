{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07a99592",
   "metadata": {},
   "source": [
    "### Ноутбук для отладки пайплайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d01281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ML / обучение\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# MLOps\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import joblib\n",
    "\n",
    "# проверка данных\n",
    "from deepchecks.tabular import Dataset\n",
    "from deepchecks.tabular.suites import data_integrity\n",
    "\n",
    "# анализ дрейфа\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "\n",
    "# API\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import uvicorn\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b336d1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузка исходного датасета Iris\n",
    "# переименование целевой колонки в 'label'.\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "df = iris.frame\n",
    "df = df.rename(columns={\"target\": \"label\"})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48080994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Integrity Suite:\n",
      "Deepchecks report saved to reports/deepchecks_report.html\n"
     ]
    }
   ],
   "source": [
    "# анализ качества исходного датасета Iris с помощью Deepchecks.\n",
    "# используем весь df без дополнительных копий.\n",
    "\n",
    "train_ds = Dataset(\n",
    "    df.drop(columns=[\"label\"]),\n",
    "    label=df[\"label\"],\n",
    "    cat_features=[]  # во всех признаках Iris — числовые значения\n",
    ")\n",
    "\n",
    "suite = data_integrity()\n",
    "result = suite.run(train_ds)\n",
    "\n",
    "os.makedirs(\"reports\", exist_ok=True)\n",
    "dc_report_path = os.path.join(\"reports\", \"deepchecks_report.html\")\n",
    "result.save_as_html(dc_report_path)\n",
    "\n",
    "print(\"Data Integrity Suite:\")\n",
    "print(f\"Deepchecks report saved to {dc_report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02730fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvidentlyAI отчёт сохранён в reports/evidently_report.html\n"
     ]
    }
   ],
   "source": [
    "def evidently_analysis(df):\n",
    "    # анализ дрейфа данных с EvidentlyAI\n",
    "    # разделение данных на референсные и текущие (70/30)\n",
    "    reference_data = df.sample(frac=0.7, random_state=42)\n",
    "    current_data = df.drop(reference_data.index)\n",
    "\n",
    "    # создание отчёта с пресетом дрейфа данных\n",
    "    report = Report(metrics=[DataDriftPreset()])\n",
    "    report.run(\n",
    "        reference_data=reference_data,\n",
    "        current_data=current_data\n",
    "    )\n",
    "\n",
    "    # сохранение HTML-отчёта\n",
    "    os.makedirs(\"reports\", exist_ok=True)\n",
    "    output_path = \"reports/evidently_report.html\"\n",
    "    report.save_html(output_path)\n",
    "\n",
    "    print(f\"EvidentlyAI отчёт сохранён в {output_path}\")\n",
    "    return report\n",
    "\n",
    "\n",
    "# запуск анализа дрейфа\n",
    "evidently_report = evidently_analysis(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87978a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olltumuct/Projects/HW5_CI_CD/.venv/lib/python3.11/site-packages/mlflow/types/utils.py:407: UserWarning:\n",
      "\n",
      "Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cefc2ddd6a9b461395d085b5b07e766d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9000, F1_macro: 0.8997\n",
      "Run id: 1f0e55a924114711aa0b2b2b34cdff42\n"
     ]
    }
   ],
   "source": [
    "def mlflow_experiment(df):\n",
    "    # запуск MLflow-эксперимента\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "\n",
    "    # подготовка данных\n",
    "    X = df.drop(columns=[\"label\"])\n",
    "    y = df[\"label\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.2,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=y,\n",
    "    )\n",
    "\n",
    "    # настройка MLflow с проверкой директорий\n",
    "    tracking_uri_env = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "    if tracking_uri_env:\n",
    "        mlflow.set_tracking_uri(tracking_uri_env)\n",
    "    else:\n",
    "        mlruns_root = os.path.abspath(\"./mlruns\")\n",
    "        trash_dir = os.path.join(mlruns_root, \".trash\")\n",
    "\n",
    "        # если существует и не директория — ошибка конфигурации\n",
    "        if os.path.exists(mlruns_root) and not os.path.isdir(mlruns_root):\n",
    "            raise RuntimeError(\n",
    "                f\"Путь {mlruns_root} существует и не является директорией. \"\n",
    "                f\"Удалите/переименуйте этот файл.\"\n",
    "            )\n",
    "\n",
    "        os.makedirs(mlruns_root, exist_ok=True)\n",
    "        os.makedirs(trash_dir, exist_ok=True)\n",
    "\n",
    "        mlflow.set_tracking_uri(f\"file:{mlruns_root}\")\n",
    "\n",
    "    mlflow.set_experiment(\"iris_hw5\")\n",
    "\n",
    "    with mlflow.start_run(run_name=\"rf_iris_baseline\"):\n",
    "        params = {\n",
    "            \"n_estimators\": 100,\n",
    "            \"max_depth\": 10,\n",
    "            \"random_state\": RANDOM_STATE,\n",
    "        }\n",
    "\n",
    "        model = RandomForestClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "        # логирование гиперпараметров и метрик\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_metric(\"f1_macro\", f1)\n",
    "\n",
    "        # пример входных данных для UI\n",
    "        input_example = X_test.iloc[:5]\n",
    "\n",
    "        # логирование модели в MLflow\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model,\n",
    "            artifact_path=\"model\",\n",
    "            input_example=input_example,\n",
    "        )\n",
    "\n",
    "        # локальный артефакт модели\n",
    "        os.makedirs(\"artifacts\", exist_ok=True)\n",
    "        model_path = \"artifacts/model.pkl\"\n",
    "        joblib.dump(model, model_path)\n",
    "\n",
    "        # логирование pkl\n",
    "        mlflow.log_artifact(model_path)\n",
    "\n",
    "        print(f\"Accuracy: {acc:.4f}, F1_macro: {f1:.4f}\")\n",
    "        print(\"Run id:\", mlflow.active_run().info.run_id)\n",
    "\n",
    "    return model, acc, f1\n",
    "\n",
    "\n",
    "# запуск эксперимента\n",
    "model, acc, f1 = mlflow_experiment(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff845d9c",
   "metadata": {},
   "source": [
    "Всё работает!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
